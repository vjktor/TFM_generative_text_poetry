{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de texto creativo con IA - Poesía"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2TokenizerFast, GPT2LMHeadModel\n",
    "from transformers import DataCollatorWithPadding, DataCollatorForLanguageModeling\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_metric\n",
    "from datasets import load_dataset\n",
    "from tokenizers import AddedToken\n",
    "import pandas as pd\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de modelo, tokenizador y ajuste de tokenizador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se carga la versión Medium del modelo GPT-2 Spanish, indicándole que el dispositivo que se usará es la GPU (CUDA: Compute Unified Device Architecture de Nvidia). Adicionalmente se le indica la ruta de la máquina local donde quedará alojado el modelo modelo descargado. El caracter'\\n' que hace la función de salto de línea, ya está en el tokenizador de este modelo, pero se agregan tokens de inicio de secuencia, fin de secuencia, tokens de padding y de caracteres desconocidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"DeepESP/gpt2-spanish-medium\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"DeepESP/gpt2-spanish-medium\", device_map=\"cuda\", cache_dir= 'I:/transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = {\n",
    "    'pad_token': '[PAD]',\n",
    "    'bos_token': '<SC>',\n",
    "    'eos_token': '<EC>',\n",
    "    'unk_token': '<UNK>'\n",
    "}\n",
    "\n",
    "# Modifica los tokens especiales del tokenizador\n",
    "tokenizer.add_special_tokens(special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adquisición de conjunto de datos de poesía, limpieza y pre-procesado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se carga el conjunto de datos que contiene las poesías. Se eligen únicamente los textos en español y se pre-procesa el conjunto de datos, agregándole los tokens representarán el inicio y final de cada poesía. Despues, se tokeniza el conjunto de datos, truncandolos a 512 máximo de longitud y se realiza padding para rellenar aquellos textos que tenga una longitud menor. Finalmente se declara el data collator que se usará en el entrenamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el conjunto de datos\n",
    "dataset = load_dataset(\"linhd-postdata/poesias\")\n",
    "\n",
    "# Acceder a la información del conjunto de datos\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_spanish = dataset.filter(lambda example: example['language'] == 'es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_ds(example):\n",
    "  example[\"text\"] = \"<SC>\" + example['text'] + \"<EC>\"\n",
    "  return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_spanish = dataset_spanish.map(format_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = dataset_spanish.map(\n",
    "    lambda example: tokenizer(example[\"text\"], max_length=512, truncation=True),\n",
    "    batched=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer,  mlm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento y evaluación por época"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En training_args se definen los argumentos principales de entrenamiento del modelo y esto alimenta el trainer, que se usará para entrenar el modelo y realizar la evaluación por época."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='I:/transformers/gtp2spamedium',\n",
    "    learning_rate= 0.0001, #2e-5,\n",
    "    save_steps = 1000000,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    do_eval = True,\n",
    "    evaluation_strategy  = 'epoch',\n",
    "    eval_steps = 1\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data['train'],\n",
    "    eval_dataset=tokenized_data['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardado del modelo y métricas de rendimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo entrenado y las métricas de rendimiento se guardan en el equipo local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save_pretrained(\"C:/Users/Victor/OneDrive/Documentos/MasterIA/09_TFM/desarrollo/modelosfinal/modelos_generadores/gpt2_spa_medium_poesia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logh = trainer.state.log_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = []\n",
    "\n",
    "# Itera sobre cada diccionario en la lista 'data'\n",
    "for entry in logh:\n",
    "    # Extrae las claves 'loss', 'step' y 'eval_loss' de cada diccionario\n",
    "    extracted_entry = {'loss': entry.get('loss', None),\n",
    "                       'step': entry.get('step', None),\n",
    "                       'eval_loss': entry.get('eval_loss', None)}\n",
    "\n",
    "    # Agrega el diccionario extraído a la nueva lista\n",
    "    extracted_data.append(extracted_entry)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un DataFrame de pandas con los datos extraídos\n",
    "df = pd.DataFrame(extracted_data)\n",
    "csv_file_path = 'C:/Users/Victor/OneDrive/Documentos/MasterIA/09_TFM/desarrollo/modelosfinal/metricas_modelo/loss_gpt2_spa_medium.csv'\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Despliegue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga de modelo, tokenizador y ajuste de tokenizador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se carga el modelo almacenado, así como el tokenizador original que se vuelve a ajustar para incluir el caracter '\\n'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_modelo = \"C:/Users/Victor/OneDrive/Documentos/MasterIA/09_TFM/desarrollo/modelosfinal/modelos_generadores/gpt2_spa_medium_poesia\"\n",
    "# Cargar el tokenizador y el modelo\n",
    "model = GPT2LMHeadModel.from_pretrained(ruta_modelo, device_map=\"cuda\")\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"DeepESP/gpt2-spanish-medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = {\n",
    "    'pad_token': '[PAD]',\n",
    "    'bos_token': '<SC>',\n",
    "    'eos_token': '<EC>',\n",
    "    'unk_token': '<UNK>'\n",
    "}\n",
    "\n",
    "# Modifica los tokens especiales del tokenizador\n",
    "tokenizer.add_special_tokens(special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función generadora de poesía"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir del modelo cargado, se crea esta función generadora de texto, la cual se alimenta de una entrada textual y genera la poesía. Se declara el argumento do_sample a True para que genere diferentes poesías con la misma entrada. El argumento temperatura controla la aleatoriedad de la generación. Valores bajos producen texto mas conservador eligiendo palabras mas probables. Valores altos produce mayor variabilidad y creatividad en la generación. Un valor en 0.95 garantiza variabilidad y creatividad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_texto(Texto):\n",
    "    input_ids = tokenizer.encode(Texto, return_tensors=\"pt\").to('cuda')\n",
    "\n",
    "    # Generar texto condicionalmente\n",
    "    output = model.generate(input_ids, max_length=250, min_length=100,pad_token_id=tokenizer.eos_token_id,\n",
    "                        #repetition_penalty = 1.2, num_beams=1, \n",
    "                        #num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95, \n",
    "                        temperature=0.95, do_sample=True,)\n",
    "\n",
    "# Decodificar y mostrar el texto generado\n",
    "    texto_generado = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "\n",
    "    \n",
    "    #texto_generado = \"Texto generado por el modelo...\" # Aquí deberías llamar a tu modelo generativo para generar texto\n",
    "    \n",
    "    return texto_generado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interfaz web para generar poesía con Gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando la libreria Gradio, a partir de la función anterior, se genera una interfaz web que permite ingresar un texto inicial y así generar poesía a partir de dicho texto. La interfaz permite interactuar con ella en el presente notebook o mediante un link web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interfaz = gr.Interface(\n",
    "    fn=generar_texto,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"Generador de Poesía\",\n",
    "    description=\"Introduce un texto inicial y genera poesía\",\n",
    "    allow_flagging = 'never',\n",
    "    clear_btn = 'Nueva Poesía',\n",
    "    submit_btn = 'Crea Poesía'\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se lanza la interfaz web por medio de launch()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interfaz.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cierra la interfaz web por medio de close()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interfaz.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
