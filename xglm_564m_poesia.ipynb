{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de texto creativo con IA - Poesía"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XGLMTokenizer, XGLMForCausalLM\n",
    "from transformers import DataCollatorWithPadding, DataCollatorForLanguageModeling\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_metric\n",
    "from datasets import load_dataset\n",
    "from tokenizers import AddedToken\n",
    "import pandas as pd\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de modelo, tokenizador y ajuste de tokenizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = XGLMTokenizer.from_pretrained(\"facebook/xglm-564M\")\n",
    "model = XGLMForCausalLM.from_pretrained(\"facebook/xglm-564M\", device_map=\"cuda\", cache_dir= 'I:/transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = {\n",
    "    'additional_special_tokens': [AddedToken('\\n')]\n",
    "}\n",
    "\n",
    "# Modifica los tokens especiales del tokenizador\n",
    "tokenizer.add_special_tokens(special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adquisición de conjunto de datos de poesía, limpieza y pre-procesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el conjunto de datos\n",
    "dataset = load_dataset(\"linhd-postdata/poesias\")\n",
    "\n",
    "# Acceder a la información del conjunto de datos\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_spanish = dataset.filter(lambda example: example['language'] == 'es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_ds(example):\n",
    "  example[\"text\"] = \"<s>\" + example['text'] + \"</s>\"\n",
    "  return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_spanish = dataset_spanish.map(format_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = dataset_spanish.map(\n",
    "    lambda example: tokenizer(example[\"text\"], max_length=512, truncation=True),\n",
    "    batched=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer,  mlm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento y evaluación por época"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='I:/transformers/xglmsmall3',\n",
    "    learning_rate= 0.0001, #2e-5,\n",
    "    save_steps = 1000000,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.0001,\n",
    "    gradient_accumulation_steps=2,\n",
    "    do_eval = True,\n",
    "    evaluation_strategy  = 'epoch',\n",
    "    eval_steps = 1\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data['train'],\n",
    "    eval_dataset=tokenized_data['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardado del modelo y métricas de rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save_pretrained(\"C:/Users/Victor/OneDrive/Documentos/MasterIA/09_TFM/desarrollo/modelosfinal/modelos_generadores/xglm_512m_poesia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logh = trainer.state.log_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = []\n",
    "\n",
    "# Itera sobre cada diccionario en la lista 'data'\n",
    "for entry in logh:\n",
    "    # Extrae las claves 'loss', 'step' y 'eval_loss' de cada diccionario\n",
    "    extracted_entry = {'loss': entry.get('loss', None),\n",
    "                       'step': entry.get('step', None),\n",
    "                       'eval_loss': entry.get('eval_loss', None)}\n",
    "\n",
    "    # Agrega el diccionario extraído a la nueva lista\n",
    "    extracted_data.append(extracted_entry)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un DataFrame de pandas con los datos extraídos\n",
    "df = pd.DataFrame(extracted_data)\n",
    "csv_file_path = 'C:/Users/Victor/OneDrive/Documentos/MasterIA/09_TFM/desarrollo/modelosfinal/metricas_modelo/loss_xglm_512m.csv'\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Despliegue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga de modelo, tokenizador y ajuste de tokenizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_modelo = \"C:/Users/Victor/OneDrive/Documentos/MasterIA/09_TFM/desarrollo/modelosfinal/modelos_generadores/xglm_512m_poesia\"\n",
    "# XGLMTokenizerFast, XGLMForCausalLM\n",
    "# Cargar el tokenizador y el modelo\n",
    "model = XGLMForCausalLM.from_pretrained(ruta_modelo, device_map=\"cuda\")\n",
    "tokenizer = XGLMTokenizerFast.from_pretrained(\"facebook/xglm-564M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = {\n",
    "    'additional_special_tokens': [AddedToken('\\n')]\n",
    "}\n",
    "\n",
    "# Modifica los tokens especiales del tokenizador\n",
    "tokenizer.add_special_tokens(special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función generadora de poesía"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_texto(Texto):\n",
    "    input_ids = tokenizer.encode(Texto, return_tensors=\"pt\").to('cuda')\n",
    "\n",
    "    # Generar texto condicionalmente\n",
    "    output = model.generate(input_ids, max_length=250, min_length=100,pad_token_id=tokenizer.eos_token_id,\n",
    "                        #repetition_penalty = 1.2, num_beams=1, \n",
    "                        #num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95, \n",
    "                        temperature=0.95, do_sample=True,)\n",
    "\n",
    "# Decodificar y mostrar el texto generado\n",
    "    texto_generado = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "\n",
    "    \n",
    "    #texto_generado = \"Texto generado por el modelo...\" # Aquí deberías llamar a tu modelo generativo para generar texto\n",
    "    \n",
    "    return texto_generado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interfaz web para generar poesía con Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interfaz = gr.Interface(\n",
    "    fn=generar_texto,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"Generador de Poesía\",\n",
    "    description=\"Introduce un texto inicial y genera poesía\",\n",
    "    allow_flagging = 'never',\n",
    "    clear_btn = 'Nueva Poesía',\n",
    "    submit_btn = 'Crea Poesía'\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interfaz.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interfaz.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
